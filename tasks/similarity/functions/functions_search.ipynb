{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"YnuwLmNmJKvz"},"outputs":[],"source":["! pip install transformers > /dev/null\n","! pip install tqdm > /dev/null"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xGQwuuxweugT"},"outputs":[],"source":["import sys\n","#sys.path.append(\"/home/jovyan/palmtree/code/\")\n","sys.path.append(\"/home/jovyan/work/olivetree/palmtree/code\")\n","sys.path.append(\"/home/jovyan/work/olivetree/final_for_paper/Graph-Matching-Networks\")"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":1850,"status":"ok","timestamp":1648206764283,"user":{"displayName":"marco mormando","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04156205142238414005"},"user_tz":-60},"id":"zqrdw6wdeugT","outputId":"b588e63e-e5fd-4fb3-f1e5-65720f75306a"},"outputs":[{"name":"stderr","output_type":"stream","text":["`fused_weight_gradient_mlp_cuda` module not found. gradient accumulation fusion with weight gradient computation disabled.\n"]}],"source":["# General imports\n","import os\n","import time\n","import json\n","import random\n","import itertools\n","from tqdm import tqdm\n","\n","# pytorch imports\n","import torch\n","import torchmetrics\n","import pytorch_lightning as pl\n","from torch.utils.data import Dataset, DataLoader\n","from torchmetrics import Accuracy, MetricCollection, Precision, Recall\n","\n","# Transformer imports\n","from transformers import BertTokenizerFast\n","from transformers import BertForPreTraining, BertForMaskedLM\n","\n","# Palmtree imports\n","from palmtree import dataset\n","from palmtree import model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"V-twyDpkeugU"},"outputs":[],"source":["os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n","os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"6\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tqfgVwQNeugV"},"outputs":[],"source":["# in common\n","base_path = \"/home/jovyan/work/olivetree/final_for_paper\"\n","\n","base_data_path = os.path.join(base_path, \"tests_cagate\", \"similarity\", \"functions\", \"data\")\n","test_name = \"test_functions_others_DEFINITIVE_nDCG.csv\"\n","test_path = os.path.join(base_data_path, \"definitive\", test_name)\n","base_res_path = os.path.join(base_path, \"tests_cagate\", \"similarity\", \"functions\", \"search_results\")\n","\n","# for olivetree\n","base_olivetree = os.path.join(base_path, \"models\")\n","base_olivetree_finetuned = os.path.join(base_path, \"tests_cagate\", \"similarity\", \"functions\", \"fine_tuned_models\", \"olivetree\")\n","tokenizer_path = os.path.join(base_path, \"tokenizer\")\n","w_tokenizer_path = os.path.join(base_path, \"whitespace_tokenizer\")\n","w2_tokenizer_path = os.path.join(base_path, \"whitespace_tokenizer2\")\n","u_tokenizer_path = os.path.join(base_path, \"unigram_tokenizer\")\n","\n","# for palmtree\n","base_palmtree = os.path.join(base_path, \"..\", \"palmtree\", \"models\")\n","base_palmtree_finetuned = os.path.join(base_path, \"tests_cagate\", \"similarity\", \"functions\", \"fine_tuned_models\", \"palmtree\")\n","vocab_path = os.path.join(base_path, \"..\", \"palmtree\", \"data\", \"palmtree_complete_dataset\", \"vocab\")\n","\n","olivetree_n_layers = 13\n","palmtree_n_layers = 12\n","\n","ol_focus_layer = 11 # 0-based\n","pt_focus_layer = 10 # 0-based"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":348,"status":"ok","timestamp":1648206764625,"user":{"displayName":"marco mormando","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04156205142238414005"},"user_tz":-60},"id":"GWCeK2xreugW","outputId":"36499ef3-2118-473b-eb45-199cb2e6202a"},"outputs":[{"name":"stdout","output_type":"stream","text":["Index(['function_id', 'ot_function', 'pt_function', 'ground_truth'], dtype='object')\n","58773\n","5000\n","11.7546 28 5\n"]}],"source":["import pandas as pd\n","import numpy as np\n","\n","df = pd.read_csv(test_path, sep='\\t')\n","df = df.where(pd.notnull(df), None)\n","\n","queries = df[~df['ground_truth'].isnull()]\n","gts = [json.loads(x) for x in df[\"ground_truth\"].to_list() if x is not None]\n","lens = list(map(lambda x: len(x), gts))\n","avg = sum(lens) / len(gts)\n","\n","print(df.keys())\n","print(len(df))\n","print(len(queries))\n","print(avg, max(lens), min(lens))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":221},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1648206764625,"user":{"displayName":"marco mormando","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04156205142238414005"},"user_tz":-60},"id":"E2fcAUR6eugY","outputId":"32471b8b-133b-4c49-9fe1-1730311571f8"},"outputs":[{"name":"stdout","output_type":"stream","text":["(58773, 4)\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>function_id</th>\n","      <th>ot_function</th>\n","      <th>pt_function</th>\n","      <th>ground_truth</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>124793</td>\n","      <td>mov rax, qword ptr [rdi] NEXT_I mov rdi, qword...</td>\n","      <td>mov rax [ rdi ] NEXT_I mov rdi [ rax + 0x60 ] ...</td>\n","      <td>None</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>411134</td>\n","      <td>endbr64  NEXT_I push rbp NEXT_I mov rbp, rsp N...</td>\n","      <td>endbr64  NEXT_I push rbp NEXT_I mov rbp rsp NE...</td>\n","      <td>None</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>409896</td>\n","      <td>endbr64  NEXT_I sub rsp, 8 NEXT_I mov rax, qwo...</td>\n","      <td>endbr64  NEXT_I sub rsp 8 NEXT_I mov rax [ rsi...</td>\n","      <td>None</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>205462</td>\n","      <td>sub rsp, 8 NEXT_I mov rax, qword ptr [rsi] NEX...</td>\n","      <td>sub rsp 8 NEXT_I mov rax [ rsi ] NEXT_I mov rs...</td>\n","      <td>None</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>214913</td>\n","      <td>mov rax, qword ptr [rsi] NEXT_I mov rsi, qword...</td>\n","      <td>mov rax [ rsi ] NEXT_I mov rsi [ rax + 0x60 ] ...</td>\n","      <td>[124793, 411134, 409896, 205462, 214913, 21332...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   function_id                                        ot_function  \\\n","0       124793  mov rax, qword ptr [rdi] NEXT_I mov rdi, qword...   \n","1       411134  endbr64  NEXT_I push rbp NEXT_I mov rbp, rsp N...   \n","2       409896  endbr64  NEXT_I sub rsp, 8 NEXT_I mov rax, qwo...   \n","3       205462  sub rsp, 8 NEXT_I mov rax, qword ptr [rsi] NEX...   \n","4       214913  mov rax, qword ptr [rsi] NEXT_I mov rsi, qword...   \n","\n","                                         pt_function  \\\n","0  mov rax [ rdi ] NEXT_I mov rdi [ rax + 0x60 ] ...   \n","1  endbr64  NEXT_I push rbp NEXT_I mov rbp rsp NE...   \n","2  endbr64  NEXT_I sub rsp 8 NEXT_I mov rax [ rsi...   \n","3  sub rsp 8 NEXT_I mov rax [ rsi ] NEXT_I mov rs...   \n","4  mov rax [ rsi ] NEXT_I mov rsi [ rax + 0x60 ] ...   \n","\n","                                        ground_truth  \n","0                                               None  \n","1                                               None  \n","2                                               None  \n","3                                               None  \n","4  [124793, 411134, 409896, 205462, 214913, 21332...  "]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["print(df.shape)\n","df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HEsFmCfOSex0"},"outputs":[],"source":["class HParams():\n","    lstm_hidden_size = 128\n","    lstm_num_layers  = 2\n","    lstm_dropout     = 0\n","    learning_rate    = 0.0001\n","    dropout          = 0.2\n","\n","class SiameseFinenuting(pl.LightningModule):\n","\n","    def __init__(self, hparams, vocab, pt_model_path, batch_size=16, result_dir=None):\n","\n","        super().__init__()\n","\n","        self.batch_size = batch_size\n","        # self.hparams = hparams\n","        self.result_dir = result_dir\n","\n","        self.pt_embedding = torch.load(pt_model_path)\n","\n","        self.lstm  = torch.nn.LSTM(input_size   = self.pt_embedding.hidden,\n","                           hidden_size  = hparams.lstm_hidden_size,\n","                           num_layers   = hparams.lstm_num_layers,\n","                           dropout      = hparams.lstm_dropout,\n","                           batch_first  = True,\n","                           bidirectional= True)\n","\n","        self.cosine = torch.nn.CosineSimilarity(dim=1, eps=1e-6)\n","\n","        # Criterion\n","        self.loss = torch.nn.MSELoss()\n","\n","        # metrics\n","        self.train_auc = torchmetrics.AUROC()\n","        self.val_auc = torchmetrics.AUROC()\n","\n","    def samples_embedding(self, batch):\n","\n","        token_ids = batch[\"token_ids\"]\n","        num_functions_ins = batch[\"num_functions_ins\"]\n","        masks = batch[\"masks\"]\n","        seq_lens = batch[\"seq_lens\"]\n","\n","        outputs = self.pt_embedding.encode_last(token_ids, torch.tensor(1, device=\"cuda\"))\n","\n","        # instruction embeddings\n","        denom = torch.sum(masks, -1, keepdim=True)\n","        denom[denom==0] = 1 # avoid zero denominator\n","        instructions_emb = torch.sum(outputs * masks.unsqueeze(-1), dim=1) / denom\n","        functions_outputs = torch.stack(torch.split(instructions_emb,num_functions_ins))\n","\n","        # sample embedding\n","        # len_mask = (torch.arange(max(seq_lens),device=\"cuda\").expand(len(seq_lens), max(seq_lens)) < seq_lens.unsqueeze(1)).type(torch.uint8)\n","        # denom = torch.sum(len_mask, -1, keepdim=True)\n","        # denom[denom==0] = 1 # avoid zero denominator\n","        # sample_emb = torch.sum(functions_outputs * len_mask.unsqueeze(-1), dim=1) / denom\n","        functions_outputs = torch.nn.utils.rnn.pack_padded_sequence(functions_outputs,\n","                                                          seq_lens,\n","                                                          batch_first=True,\n","                                                          enforce_sorted=False)\n","\n","        outputs, _ = lstm_output = self.lstm(functions_outputs)\n","\n","        unpacked, unpacked_len = torch.nn.utils.rnn.pad_packed_sequence(outputs,\n","                                                                        batch_first=True)\n","\n","        sum_unpacked = unpacked.sum(1)\n","        avgs = sum_unpacked/unpacked_len.unsqueeze(-1).to(\"cuda\")\n","\n","        return avgs\n","\n","    def forward(self, asm_input):\n","\n","        result = {}\n","\n","        first_embeddings = self.samples_embedding(asm_input[\"first\"])\n","        second_embeddings = self.samples_embedding(asm_input[\"second\"])\n","\n","        cosines = self.cosine(first_embeddings, second_embeddings)\n","\n","        result['prediction'] = cosines\n","        result['labels'] = asm_input[\"labels\"]\n","\n","        return result\n","\n","    def training_step(self, batch, batch_idx):\n","        forward_output = self.forward(batch)\n","\n","        prediction = forward_output[\"prediction\"]\n","        labels = forward_output[\"labels\"]\n","\n","        loss = self.loss(prediction, labels.float())\n","\n","        l2 = labels.clone()\n","        l2[l2==-1]=0\n","        # self.train_auc.update(prediction, l2)\n","        m = self.train_auc(prediction, l2)\n","\n","        self.log('train_loss', loss, on_step=True, on_epoch=True, prog_bar=True, logger=True, batch_size=self.batch_size)\n","        self.log('train_auc', m, on_step=False, on_epoch=True, prog_bar=True, logger=True, batch_size=self.batch_size)\n","\n","        return {\"loss\":loss,\n","                \"train_auc\":m}\n","\n","    def validation_step(self, batch, batch_idx):\n","        forward_output = self.forward(batch)\n","\n","        prediction = forward_output[\"prediction\"]\n","        labels = forward_output[\"labels\"]\n","\n","        loss = self.loss(prediction, labels.float())\n","\n","        l2 = labels.clone()\n","        l2[l2==-1]=0\n","        # self.val_auc.update(prediction, l2)\n","        m = self.val_auc(prediction, l2)\n","\n","        self.log('val_loss', loss, on_step=True, on_epoch=True, prog_bar=True, logger=True, batch_size=self.batch_size)\n","        self.log('val_auc', m, on_step=False, on_epoch=True, prog_bar=True, logger=True, batch_size=self.batch_size)\n","\n","        return {\"loss\":loss,\n","                \"val_auc\":m}\n","\n","    def test_step(self, batch, batch_idx):\n","        forward_output = self.forward(batch)\n","\n","        prediction = forward_output[\"prediction\"]\n","        labels = forward_output[\"labels\"]\n","\n","        loss = self.loss(prediction, labels.float())\n","\n","        l2 = labels.clone()\n","        l2[l2==-1]=0\n","        # self.val_auc.update(prediction, l2)\n","        m = self.val_auc(prediction, l2)\n","\n","        self.log('val_loss', loss, on_step=True, on_epoch=True, prog_bar=True, logger=True, batch_size=self.batch_size)\n","        self.log('val_auc', m, on_step=False, on_epoch=True, prog_bar=True, logger=True, batch_size=self.batch_size)\n","\n","        # print(m)\n","\n","        return {\"loss\":loss,\n","                \"val_auc\":m,\n","                \"prediction\": prediction,\n","                \"labels\": l2}\n","\n","    def test_epoch_end(self, outputs):\n","\n","        predictions = []\n","        references = []\n","\n","        for elem in outputs:\n","            predictions.extend(elem[\"prediction\"].cpu().detach().numpy())\n","            references.extend(elem[\"labels\"].cpu().detach().numpy())\n","\n","        compute_roc(references, predictions, self.result_dir)\n","\n","    def configure_optimizers(self):\n","        optimizer = torch.optim.Adam(self.parameters(), lr=LEARNING_RATE)\n","        return optimizer"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sx_IQa2meugY"},"outputs":[],"source":["def parse_func_search_csv(df, start, end, is_olivetree=True):\n","    rows = []\n","\n","    df_slice = df.iloc[start:end, 0:df.shape[1]]\n","    for index, row in df_slice.iterrows():\n","        if is_olivetree:\n","            #if row[3] is None:\n","            info = [\" \".join(row[\"ot_function\"].split(\" NEXT_I \"))]\n","            #else:\n","            #    info = [\" \".join(row[1].split(\" NEXT_I \"))]\n","        else:\n","            #if row[3] is None:\n","            info = row[\"pt_function\"].split(\" NEXT_I \")[:512]\n","            #else:\n","            #    info = row[2].split(\" NEXT_I \")\n","\n","        if row[3] is not None:\n","            g_t = json.loads(row[\"ground_truth\"])\n","            g_t = list(map(lambda x: int(x), g_t))\n","        else:\n","            g_t = None\n","\n","        parsed_row = (int(row[\"function_id\"]), info, g_t)\n","        rows.append(parsed_row)\n","\n","    return rows"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_ydmpO2TeugZ"},"outputs":[],"source":["def load_olivetree_model(tokenizer_path, best_checkpoint, mlm=False):\n","\n","    print(\"Loading Tokenizer ->\", tokenizer_path)\n","    tokenizer =  BertTokenizerFast.from_pretrained(tokenizer_path)\n","\n","    print(\"Loading Model ->\", best_checkpoint)\n","    if not mlm:\n","        model = BertForPreTraining.from_pretrained(best_checkpoint, output_hidden_states=True)\n","    else:\n","        model = BertForMaskedLM.from_pretrained(best_checkpoint, output_hidden_states=True)\n","\n","    model.to(\"cuda\")\n","    model.eval()\n","\n","    return tokenizer, model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-kp4BHK-eugZ"},"outputs":[],"source":["def load_palmtree_model(vocab_path, best_checkpoint):\n","\n","    print(\"Loading Vocab ->\", vocab_path)\n","    vocab = dataset.WordVocab.load_vocab(vocab_path)\n","\n","    print(\"Loading Model ->\", best_checkpoint)\n","    bert = model.BERT(len(vocab), hidden=128, n_layers=12, attn_heads=8, dropout=0.0)\n","    bert_model = torch.load(best_checkpoint)\n","\n","    bert_model.eval()\n","    bert_model.to(\"cuda\")\n","\n","    return vocab, bert_model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XHevtP5TSex0"},"outputs":[],"source":["def load_palmtree_lstm_model(vocab_path, best_checkpoint):\n","\n","    print(\"Loading Vocab ->\", vocab_path)\n","    vocab = dataset.WordVocab.load_vocab(vocab_path)\n","\n","    print(\"Loading Model ->\", best_checkpoint)\n","    model = SiameseFinenuting(hparams=HParams(), vocab=vocab, pt_model_path=os.path.join(base_palmtree, \"complete_palmtree_model\", \"transformer.ep0\"))\n","    checkpoint = torch.load(best_checkpoint)\n","    model.load_state_dict(checkpoint[\"state_dict\"])\n","\n","    model.eval()\n","    model.to(\"cuda\")\n","\n","    return vocab, model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TbB1wVyleuga"},"outputs":[],"source":["# olivetree\n","from time import time\n","from math import ceil\n","from tqdm.notebook import tqdm\n","\n","def compute_embeddings_olivetree(tokenizer_path, model_path, df, layer, batch_size, is_cls=False):\n","\n","    tokenizer, model = load_olivetree_model(tokenizer_path, model_path, mlm = False if \"next\" in model_path else True)\n","    n_iterations = ceil(df.shape[0]/batch_size)\n","\n","    embeddings_list = []\n","    times = []\n","\n","    print(f\"Selected batch size {batch_size} and n iterations {n_iterations}\")\n","\n","    for i in tqdm(range(n_iterations)):\n","\n","        time_s = time()\n","\n","        start = i * batch_size\n","        end = (i+1) * batch_size\n","\n","        functions = parse_func_search_csv(df, start, end, is_olivetree=True)\n","\n","        batch_functions = []\n","        for f in functions:\n","            batch_functions.extend(f[1])\n","\n","\n","\n","        tokenized_functions = tokenizer(batch_functions, padding=True, truncation=True, max_length=512)\n","\n","        for key, value in tokenized_functions.items():\n","            tokenized_functions[key] = torch.tensor(value, device=\"cuda\")\n","\n","        with torch.no_grad():\n","            output = model(**tokenized_functions)\n","\n","        #for l, layer in enumerate(layers):\n","            # for each layer computing the embeddings of the batch\n","        for i, hidden_layer in enumerate(output.hidden_states[layer]):\n","            if is_cls:\n","                function_embedding = hidden_layer[0]\n","            else:\n","                function_embedding = torch.mean(hidden_layer[tokenized_functions['attention_mask'][i].type(torch.bool)], 0)\n","            embeddings_list.append(function_embedding.cpu())\n","\n","        #strands_matrix = torch.stack(strands_embeddings).to(\"cuda\")\n","        #bbs_embeddings = torch.split(strands_matrix, batch_strands_sizes)\n","\n","        #bbs_embeddings = [bb.mean(dim=0) for bb in bbs_embeddings]\n","        #embeddings_list.extend(strands_embeddings)\n","\n","        for k in list(tokenized_functions):\n","            del tokenized_functions[k]\n","        del output\n","        torch.cuda.empty_cache()\n","\n","        time_t = time() - time_s\n","        times.append(time_t)\n","\n","    ids = df['function_id'].tolist()\n","    print(len(ids), len(embeddings_list))\n","    assert(len(ids) == len(embeddings_list))\n","\n","    print(model_path)\n","    print(f\"BinBert took {sum(times)/len(times)} seconds on avg to compute embeddings of a {batch_size} batch of functions\")\n","    print(f\"And in total {sum(times)} seconds for {df.shape[0]} functions\")\n","\n","    return ids, embeddings_list"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"d6RdIV0sSex0"},"outputs":[],"source":["# palmtree finetuned\n","from math import ceil\n","from tqdm.notebook import tqdm\n","\n","def _pad(elem, max_instr_batch, max_tok_batch, vocab):\n","\n","        masks = []\n","        batch_token_ids = []\n","\n","        num_pad_inst = max_instr_batch - len(elem)\n","\n","        for j, instr in enumerate(elem):\n","\n","            num_pad_tok = max_tok_batch - len(instr)\n","            batch_token_ids.append(instr + [vocab.pad_index] * num_pad_tok)\n","            masks.append([1] * len(instr) + [0] * num_pad_tok)\n","\n","        batch_token_ids += [[vocab.pad_index] * max_tok_batch] * num_pad_inst\n","        masks += [[0] * max_tok_batch] * num_pad_inst\n","\n","        return masks, batch_token_ids\n","\n","def prepare_for_palmtree_lstm(strands, vocab):\n","\n","    # firstly, tokenize each instruction of each strand\n","    # returns list (strands) of list (instructions) of list of tokens\n","    tok_instr_list = []\n","    for strand in strands:\n","        tok_instr = [[vocab.sos_index] + [vocab.stoi.get(tok, vocab.unk_index) for tok in instr.split()] +\n","                     [vocab.eos_index] for instr in strand]\n","        tok_instr_list.append(tok_instr)\n","\n","    # finds max num ins for strand\n","    max_instr_batch = max([len(strand) for strand in tok_instr_list])\n","    # finds max num tokens for instruction for strand\n","    max_tok_batch = max([len(instr) for strand in tok_instr_list for instr in strand])\n","\n","    masks = []\n","    seq_lens = []\n","    batch_token_ids = []\n","\n","    for elem in tok_instr_list:\n","\n","        seq_lens.append(len(elem))\n","        s_masks, s_batch_token_ids = _pad(elem, max_instr_batch, max_tok_batch, vocab)\n","        masks.extend(s_masks)\n","        batch_token_ids.extend(s_batch_token_ids)\n","\n","    batch_result = {\"num_functions_ins\": max_instr_batch,\n","                    \"token_ids\": torch.tensor(batch_token_ids, device=\"cuda\"),\n","                    \"masks\": torch.tensor(masks, device=\"cuda\"),\n","                    \"seq_lens\":  seq_lens}\n","\n","    return batch_result\n","\n","def compute_embeddings_palmtree_lstm(vocab_path, model_path, df, batch_size):\n","\n","    vocab, model = load_palmtree_lstm_model(vocab_path, model_path)\n","    n_iterations = ceil(df.shape[0]/batch_size)\n","\n","    embeddings_list = []\n","    times = []\n","\n","    print(f\"Selected batch size {batch_size} and n iterations {n_iterations}\")\n","\n","    for i in tqdm(range(n_iterations)):\n","\n","        time_s = time()\n","\n","        start = i * batch_size\n","        end = (i+1) * batch_size\n","\n","        functions = parse_func_search_csv(df, start, end, is_olivetree=False)\n","\n","        #for each strand I have list of instructions\n","        batch_result = prepare_for_palmtree_lstm(list(map(lambda x: x[1], functions)), vocab)\n","\n","        with torch.no_grad():\n","            embeddings = model.samples_embedding(batch_result)\n","\n","        embeddings_list.extend(embeddings)\n","\n","        torch.cuda.empty_cache()\n","\n","        time_t = time() - time_s\n","        times.append(time_t)\n","\n","    ids = df['function_id'].tolist()\n","    print(len(ids), len(embeddings_list))\n","    assert(len(ids) == len(embeddings_list))\n","\n","    print(model_path)\n","    print(f\"Palmtree took {sum(times)/len(times)} seconds on avg to compute embeddings of a {batch_size} batch of functions\")\n","    print(f\"And in total {sum(times)} seconds for {df.shape[0]} functions\")\n","\n","    return ids, embeddings_list"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RMA_4LRQeugd"},"outputs":[],"source":["# class for making fast cosine similarity\n","from operator import itemgetter\n","import torch.nn.functional as F\n","\n","class SearchEngine:\n","\n","    def __init__(self, checkpoint, ids_filename, layer):\n","        self.layer = layer\n","        self.ids = json.load(open(os.path.join(checkpoint, ids_filename), \"r\"))\n","        print(len(self.ids))\n","        self.matrix = torch.load(os.path.join(checkpoint, f\"embeddings_layer_{layer}.pt\"))\n","        self.matrix.to(\"cuda\")\n","\n","    def find_top_k(self, id_to_query, k):\n","        res = []\n","        scores = []\n","        idx = self.ids.index(id_to_query)\n","\n","        embedding_to_query = torch.clone(self.matrix[idx])\n","        embedding_to_query.to(\"cuda\")\n","\n","        dist = F.cosine_similarity(self.matrix, embedding_to_query)\n","\n","        index_sorted = torch.argsort(dist, descending=True)\n","        top_k = index_sorted[:k]\n","\n","        res.extend([self.ids[k] for k in top_k])\n","        scores.extend([dist[k].item() for k in top_k])\n","\n","        return res, scores\n","\n","    def find_top_k_batch(self, ids_to_query, k):\n","        # list of lists\n","        res = []\n","        scores = []\n","\n","        idxs = []\n","        for idx in ids_to_query:\n","            idxs.append(self.ids.index(idx))\n","\n","        m_query = []\n","        for idx in idxs:\n","            m_query.append(torch.clone(self.matrix[idx]))\n","\n","        m_query = torch.stack(m_query)\n","        m_query.to(\"cuda\")\n","\n","        a_norm = self.matrix / self.matrix.norm(dim=-1)[:, None]\n","        b_norm = m_query / m_query.norm(dim=-1)[:, None]\n","\n","        # dist[i][j] = dist(b_norm[i] * a_norm[j])\n","        dist = torch.mm(b_norm, a_norm.transpose(0,1))\n","\n","        for i in range(len(ids_to_query)):\n","            index_sorted = torch.argsort(dist[i], descending=True)\n","            top_k = index_sorted[:k]\n","\n","            res.append([self.ids[k] for k in top_k])\n","            scores.append([dist[i][k].item() for k in top_k])\n","\n","        return res, scores"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"u7vwRAr8eugd"},"outputs":[],"source":["from tqdm.notebook import tqdm\n","\n","def find_top_k_similar(data_path, df, batch_size, focus_layer, k):\n","\n","    queries = df[~df['ground_truth'].isnull()]\n","    SE = SearchEngine(data_path, \"functions_ids.json\", focus_layer)\n","\n","    p_bar = tqdm(total=len(queries))\n","    answers = []\n","    times = []\n","\n","    count = 0\n","    gts = []\n","    ids = []\n","\n","    for i, (index, row) in enumerate(queries.iterrows()):\n","\n","        time_s = time()\n","\n","        ground_truth = json.loads(row['ground_truth'])\n","        ground_truth = list(map(lambda x: int(x), ground_truth))\n","        gts.append(ground_truth)\n","        ids.append(row[\"function_id\"])\n","        count += 1\n","\n","        if len(ids) == batch_size or count == len(queries):\n","            top_k_lists, scores = SE.find_top_k_batch(ids, 200)\n","\n","            true_labels = []\n","            for j in range(len(top_k_lists)):\n","                true_labels.append([1 if k_id in gts[j] else 0 for k_id in top_k_lists[j]])\n","\n","            answers.extend([(true_labels[j], len(gts[j]), scores[j]) for j in range(len(top_k_lists))])\n","\n","            time_t = time() - time_s\n","            times.append(time_t)\n","\n","            p_bar.update(len(top_k_lists))\n","            gts, ids = [], []\n","\n","    print(f\"On inference it took {sum(times[:-1])/len(times[:-1])} seconds on avg\")\n","    print(f\"In total it took {sum(times)} seconds\")\n","\n","    return answers"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Y9DYmsa0euge"},"outputs":[],"source":["import math\n","import numpy as np\n","from tqdm.notebook import tqdm\n","\n","def find_dcg(element_list):\n","    dcg_score = 0.0\n","    for j, sim in enumerate(element_list):\n","        dcg_score += float(sim) / math.log(j + 2)\n","    return dcg_score\n","\n","\n","def count_ones(element_list):\n","    return len([x for x in element_list if x == 1])\n","\n","\n","def extract_info(answers):\n","\n","    # we analyze only one layer here\n","    performance1 = []\n","    average_recall_k1 = []\n","    precision_at_k1 = []\n","\n","    for f_index in tqdm(range(0, len(answers))):\n","        # each data is a tuple of 3 elements:\n","        # - [0]: list of lists 1 and 0\n","        # - [1]: num of correct answers\n","        # - [2]: list of lists of similarity scores\n","        data = answers[f_index]\n","\n","        f1 = data[0]\n","        pf1 = data[1]\n","\n","        tp1 = []\n","        recall_p1 = []\n","        precision_p1 = []\n","\n","        for k in range(1, len(f1)):\n","            cut1 = f1[0:k]\n","            dcg1 = find_dcg(cut1)\n","            ideal1 = find_dcg(([1] * (pf1) + [0] * (k - pf1))[0:k])\n","\n","            p1k = float(count_ones(cut1))\n","\n","            tp1.append(dcg1 / ideal1)\n","            recall_p1.append(p1k / pf1)\n","            precision_p1.append(p1k / k)\n","\n","        performance1.append(tp1)\n","        average_recall_k1.append(recall_p1)\n","        precision_at_k1.append(precision_p1)\n","\n","    avg_p1 = np.average(performance1, axis=0)\n","    avg_recall = np.average(average_recall_k1, axis=0)\n","    average_precision = np.average(precision_at_k1, axis=0)\n","\n","#     std_p1 = np.std(performance1, axis=0)\n","#     std_recall = np.std(average_recall_k1, axis=0)\n","#     std_precision = np.std(precision_at_k1, axis=0)\n","\n","#     return [list(avg_p1), list(std_p1)], [list(avg_recall), list(std_recall)], [list(average_precision), list(std_precision)]\n","    return list(avg_p1), list(avg_recall), list(average_precision)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"56xAiDTiSex1"},"outputs":[],"source":["infos = []\n","\n","def embeddingToNp(e):\n","    e = e.replace('\\n', '')\n","    e = e.replace('[', '')\n","    e = e.replace(']', '')\n","    emb = np.fromstring(e, dtype=float, sep=' ')\n","    return emb"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DOy7WA8fSex1","outputId":"f36c3b9d-c827-4780-e83d-5a8aca368cc4","colab":{"referenced_widgets":["1910a3d552e146ddbb9bd3eb7f10a987","9a53036e0f7142f381e1ea1cec93946e","97333a41174c4adc99fd628eae812d59"]}},"outputs":[{"name":"stdout","output_type":"stream","text":["Loading vocab @vocab/vocab.json\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1910a3d552e146ddbb9bd3eb7f10a987","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/58773 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["GEN-BOW took 0.0602505210957496 seconds on avg to compute embeddings of a 32 batch of functions\n","And in total 110.64167141914368 seconds for 58773 functions\n","58773\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9a53036e0f7142f381e1ea1cec93946e","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/5000 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["On inference it took 0.3398063794160501 seconds on avg\n","In total it took 53.108171224594116 seconds\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"97333a41174c4adc99fd628eae812d59","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/5000 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"}],"source":["# GEN-BOW\n","\n","from evaluation import *\n","from configure import *\n","from dataset import *\n","from utils import *\n","\n","config = get_default_config()\n","config['evaluation']['batch_size'] = 32\n","dataset_params = config['data']['dataset_params']\n","dataset_params['test_path'] = test_path.replace('.csv', '_CFG.csv')\n","\n","gen_base_path = os.path.join(base_path, \"Graph-Matching-Networks\")\n","\n","print(\"Loading vocab @vocab/vocab.json\")\n","vocab = json.load(open(os.path.join(gen_base_path, \"vocab/vocab.json\"), \"r\"))\n","\n","test_set = GraphFunctionSimilarityDataset(dataset_params, vocab=vocab, mode='test')\n","test_data_iter = test_set.list_cfg(config['evaluation']['batch_size'], stack=True)\n","\n","gen_model_name = \"GEN_counting_epoch20_step410892_auc_val=0.9713036599991033.pt\"\n","model = torch.load(os.path.join(gen_base_path, \"models\", \"counting_emb\", gen_model_name))\n","model.eval()\n","\n","times = []\n","\n","with torch.no_grad():\n","\n","    embeddings = []\n","    p_bar = tqdm(total=len(test_set._df))\n","    while not test_set.is_empty():\n","\n","        time_s = time()\n","\n","        batch = next(test_data_iter)\n","        node_features, edge_features, from_idx, to_idx, graph_idx, n_graphs = get_graph(batch)\n","        embds = model(node_features, edge_features.to(\"cuda\"), from_idx.to(\"cuda\"), to_idx.to(\"cuda\"),\n","                           graph_idx.to(\"cuda\"), n_graphs)\n","\n","        embeddings.append(embds)\n","\n","        time_t = time() - time_s\n","        times.append(time_t)\n","\n","        p_bar.update(n_graphs)\n","\n","print(f\"GEN-BOW took {sum(times[:-1])/len(times[:-1])} seconds on avg to compute embeddings of a {config['evaluation']['batch_size']} batch of functions\")\n","print(f\"And in total {sum(times)} seconds for {df.shape[0]} functions\")\n","\n","gen_functions_ids = test_set._df['function_id'].tolist()\n","gen_info_path = os.path.join(base_data_path, \"embeddings\", \"GEN-BOW\")\n","\n","os.makedirs(gen_info_path, exist_ok=True)\n","with open(os.path.join(gen_info_path, f\"functions_ids.json\"), \"w\") as f:\n","    json.dump(gen_functions_ids, f)\n","\n","matrix = torch.vstack(embeddings)\n","torch.save(matrix, os.path.join(gen_info_path, f\"embeddings_layer_{-1}.pt\"))\n","\n","gen_answers = find_top_k_similar(gen_info_path, test_set._df, 32, -1, 200)\n","gen_avg_p1, gen_recal_p1, gen_pre_p1 = extract_info(gen_answers)\n","\n","with open(os.path.join(gen_info_path, f\"{test_name}.json\"), \"w\") as f:\n","    json.dump([gen_avg_p1, gen_recal_p1, gen_pre_p1], f)\n","\n","# infos.append((gem_avg_p1, gem_recal_p1, gem_pre_p1))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AuUTBnruSex1"},"outputs":[],"source":["# # GEN-PT-FT\n","\n","# from evaluation import *\n","# from configure import *\n","# from dataset import *\n","# from utils import *\n","\n","# config = get_default_config()\n","# config['evaluation']['batch_size'] = 64\n","# dataset_params = config['data']['dataset_params']\n","# dataset_params['test_path'] = test_path.replace('.csv', '_CFG.csv')\n","\n","# gen_base_path = os.path.join(base_path, \"Graph-Matching-Networks\")\n","\n","# tokenizer_path = \"/home/jovyan/work/olivetree/final_for_paper/tokenizer\"\n","# transformer_path = \"/home/jovyan/work/olivetree/final_for_paper/models/next_sentence_prediction_bert_normal_mask30/checkpoint-67246\"\n","# gen_tokenizer, _ = load_olivetree_model_freezed(tokenizer_path, transformer_path,\n","#                                                               mlm=False if \"next\" in transformer_path else True)\n","\n","# test_set = GraphFunctionSimilarityDataset(dataset_params, tokenizer=gen_tokenizer, mode='test')\n","# test_data_iter = test_set.list_cfg(config['evaluation']['batch_size'], capping=True, stack=False)\n","\n","# gen_model_name = \"GEN_pt_ft_2_epoch1_step18804_auc_val=0.9817893159835158.pt\"\n","# model = torch.load(os.path.join(gen_base_path, \"models\", \"pt_freezed_emb_ft_2\", gen_model_name))\n","# model.eval()\n","\n","# with torch.no_grad():\n","\n","#     embeddings = []\n","#     p_bar = tqdm(total=len(test_set._df))\n","#     while not test_set.is_empty():\n","\n","#         batch = next(test_data_iter)\n","#         node_features, edge_features, from_idx, to_idx, graph_idx, n_graphs = get_graph(batch)\n","#         embds = model(node_features, edge_features.to(\"cuda\"), from_idx.to(\"cuda\"), to_idx.to(\"cuda\"),\n","#                            graph_idx.to(\"cuda\"), n_graphs)\n","\n","#         embeddings.append(embds)\n","#         p_bar.update(n_graphs)\n","\n","# gen_functions_ids = test_set._df['function_id'].tolist()\n","# gen_info_path = os.path.join(base_data_path, \"embeddings\", \"GEN-PT-FT\")\n","\n","# os.makedirs(gen_info_path, exist_ok=True)\n","# with open(os.path.join(gen_info_path, f\"functions_ids.json\"), \"w\") as f:\n","#     json.dump(gen_functions_ids, f)\n","\n","# matrix = torch.vstack(embeddings)\n","# torch.save(matrix, os.path.join(gen_info_path, f\"embeddings_layer_{-1}.pt\"))\n","\n","# gen_answers = find_top_k_similar(gen_info_path, test_set._df, 256, -1, 200)\n","# gen_avg_p1, gen_recal_p1, gen_pre_p1 = extract_info(gen_answers)\n","\n","# with open(os.path.join(gen_info_path, f\"{test_name}.json\"), \"w\") as f:\n","#     json.dump([gen_avg_p1, gen_recal_p1, gen_pre_p1], f)\n","\n","# # infos.append((gem_avg_p1, gem_recal_p1, gem_pre_p1))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FRIM3-fcSex1"},"outputs":[],"source":["# GMN-BOW\n","\n","from evaluation import *\n","from configure import *\n","from dataset import *\n","from utils import *\n","\n","# gpu = int(os.environ[\"CUDA_VISIBLE_DEVICES\"])\n","\n","gmn_info_path = os.path.join(base_data_path, \"embeddings\", \"GMN-BOW\")\n","\n","config = get_default_config()\n","config['evaluation']['batch_size'] = 32\n","dataset_params = config['data']['dataset_params']\n","dataset_params['test_path'] = test_path.replace('.csv', '_CFG.csv')\n","\n","gmn_base_path = os.path.join(base_path, \"Graph-Matching-Networks\")\n","\n","print(\"Loading vocab @vocab/vocab.json\")\n","vocab = json.load(open(os.path.join(gmn_base_path, \"vocab/vocab.json\"), \"r\"))\n","\n","test_set = GraphFunctionSimilarityDataset(dataset_params, vocab=vocab, mode='test')\n","\n","gmn_model_name = \"GMN_counting_epoch20_step410892_auc_val=0.9894280934953459.pt\"\n","model = torch.load(os.path.join(gmn_base_path, \"models\", \"counting\", gmn_model_name))\n","model.eval()\n","\n","times = []\n","preparations = []\n","inferences = []\n","\n","report = open(\"tmp.txt\", \"w\")\n","\n","with torch.no_grad():\n","\n","    functions_ids = test_set._df[\"function_id\"].to_list()\n","    queries = test_set._df[~test_set._df['ground_truth'].isnull()]\n","    # splits = np.array_split(queries, 3)\n","    # queries = splits[gpu]\n","\n","    gmn_answers = []\n","    for index, row in tqdm(queries.iterrows(), total=len(queries)):\n","        # print(f\"Querying {row['function_id']} -> searching for {row['ground_truth']}\")\n","\n","        test_data_iter = test_set.list_cfg(config['evaluation']['batch_size'], query_idx=index, stack=True, capping=True)\n","\n","        total_preparation = 0\n","\n","        similarities = []\n","        while not test_set.is_empty():\n","            time_s = time()\n","\n","            batch = next(test_data_iter)\n","            node_features, edge_features, from_idx, to_idx, graph_idx, n_graphs = get_graph(batch)\n","            eval_pairs = model(node_features, edge_features.to(\"cuda\"), from_idx.to(\"cuda\"), to_idx.to(\"cuda\"),\n","                               graph_idx.to(\"cuda\"), n_graphs)\n","\n","            x, y = reshape_and_split_tensor(eval_pairs, 2)\n","            sim = compute_similarity(config, x, y)\n","            similarities.append(sim)\n","\n","            time_t = time() - time_s\n","            times.append(time_t)\n","            total_preparation += time_t\n","\n","        preparations.append(total_preparation)\n","\n","        time_s = time()\n","\n","        similarities = torch.cat(similarities, -1)\n","        index_sorted = torch.argsort(similarities, descending=True)\n","        top_k = index_sorted[:200]\n","\n","        top_k_list, scores = [], []\n","        top_k_list.extend([functions_ids[k] for k in top_k])\n","        scores.extend([similarities[k].item() for k in top_k])\n","\n","        g_t = set(json.loads(row[\"ground_truth\"]))\n","        true_labels = [1 if k_id in g_t else 0 for k_id in top_k_list]\n","        gmn_answers.append((true_labels, len(g_t), scores))\n","\n","        time_t = time() - time_s\n","        inferences.append(time_t)\n","\n","    json.dump([times, preparations, inferences], report)\n","#     print(f\"Avg 64 batch embeddings: {sum(times[:-1])/len(times[:-1])} seconds\")\n","\n","#     n_64 = int(len(inferences)/64)\n","#     remoduled = [sum(inferences[i:i + 64]) for i in range(0, len(inferences), 64)]\n","\n","#     print(f\"Avg seconds on 64 query is {sum(remoduled[:-1])/len(remoduled[:-1])} seconds\")\n","#     print(f\"Total {sum(remoduled)} seconds\")\n","\n","    gmn_avg_p1, gmn_recal_p1, gmn_pre_p1 = extract_info(gmn_answers)\n","\n","    with open(os.path.join(gmn_info_path, f\"{test_name}.json\"), \"w\") as f:\n","        json.dump([gmn_avg_p1, gmn_recal_p1, gmn_pre_p1], f)\n","\n","report.close()\n","# infos.append((gmn_avg_p1, gmn_recal_p1, gmn_pre_p1))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"43b8EIJXSex1"},"outputs":[],"source":["# # FOR GMN-PT\n","# def pre_compute_nodes_features(df, tokenizer, trasformer):\n","#     nodes_features=[]\n","#     for index, row in tqdm(df.iterrows(), total=len(df)):\n","#         nodes = json.loads(row[\"nodes\"])\n","#         nodes = sorted(nodes, key=lambda d: d[\"address\"])\n","\n","#         ot_ins = list(map(lambda x: \" \".join(x[\"ot_instructions\"].split(\" NEXT_I \")), nodes))\n","#         tokenized_nodes = tokenizer(ot_ins, padding=True, truncation=True, max_length=512)\n","\n","#         for key, value in tokenized_nodes.items():\n","#             tokenized_nodes[key] = torch.tensor(value, device=\"cuda\")\n","\n","#         output = trasformer(**tokenized_nodes)\n","#         hidden_states = output.hidden_states[-1]\n","#         masks = tokenized_nodes['attention_mask']\n","#         partial_mul = hidden_states * masks.unsqueeze(-1)\n","#         partial_sum = torch.sum(partial_mul, dim=1)\n","#         n = torch.sum(masks, dim=1)\n","#         avgs = partial_sum / n.unsqueeze(-1)\n","\n","#         for k in list(tokenized_nodes):\n","#             del tokenized_nodes[k]\n","#         del output\n","#         torch.cuda.empty_cache()\n","\n","#         nodes_features.append(avgs)\n","\n","#     return nodes_features"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pI_P937tSex1"},"outputs":[],"source":["# # GMN-PT\n","\n","# import copy\n","# from evaluation import *\n","# from configure import *\n","# from dataset import *\n","# from utils import *\n","\n","# gmn_info_path = os.path.join(base_data_path, \"embeddings\", \"GMN-PT\")\n","\n","# if os.path.exists(os.path.join(gmn_info_path, \"ndcg_info.json\")):\n","#     gmn_avg_p1 = json.load(open(os.path.join(gmn_info_path, \"ndcg_info.json\"), \"r\"))\n","#     gmn_recal_p1 = json.load(open(os.path.join(gmn_info_path, \"recall_info.json\"), \"r\"))\n","#     gmn_pre_p1 =  json.load(open(os.path.join(gmn_info_path, \"precision_info.json\"), \"r\"))\n","# else:\n","#     config = get_default_config()\n","#     dataset_params = config['data']['dataset_params']\n","\n","#     gmn_base_path = os.path.join(base_path, \"Graph-Matching-Networks\")\n","\n","#     tokenizer_path = \"/home/jovyan/work/olivetree/final_for_paper/tokenizer\"\n","#     transformer_path = \"/home/jovyan/work/olivetree/final_for_paper/models/next_sentence_prediction_bert_normal_mask30/checkpoint-67246\"\n","#     gmn_tokenizer, gmn_transformer = load_olivetree_model_freezed(tokenizer_path, transformer_path,\n","#                                                                   mlm=False if \"next\" in transformer_path else True)\n","\n","#     test_set = GraphFunctionSimilarityDataset(dataset_params, mode='test')\n","\n","#     gmn_model_name = \"GMN_pt_epoch3_step410892_auc_val=0.9959328000944714.pt\"\n","#     model = torch.load(os.path.join(gmn_base_path, \"models\", \"pt_freezed\", gmn_model_name))\n","\n","#     true_model, optimizer = build_model(config, 768, 16, pt_model=gmn_transformer)\n","#     true_model.load_state_dict(model.state_dict())\n","#     true_model.to(\"cuda\")\n","#     true_model.eval()\n","\n","#     with torch.no_grad():\n","\n","#         functions_ids = test_set._df[\"function_id\"].to_list()\n","#         queries = test_set._df[~test_set._df['ground_truth'].isnull()]\n","\n","#         # memoization of tokenized nodes for each functions\n","#         print(\"Tokenization and pre-computation of nodes embeddings...\")\n","#         embeddings = pre_compute_nodes_features(test_set._df, gmn_tokenizer, true_model._pt_model)\n","#         print(len(embeddings))\n","\n","#         gmn_answers = []\n","#         for index, row in tqdm(queries.iterrows(), total=len(queries)):\n","#             test_data_iter = test_set.list_cfg(config['evaluation']['batch_size'], query_idx=index, stack=False)\n","\n","#             counter = 0\n","#             similarities = []\n","#             while not test_set.is_empty():\n","\n","#                 batch = next(test_data_iter)\n","#                 node_features, edge_features, from_idx, to_idx, graph_idx, n_graphs = get_graph(batch)\n","\n","#                 node_features = []\n","#                 for i in range(counter, counter+int(n_graphs/2)):\n","#                     if i < len(embeddings):\n","#                         node_features.extend([torch.clone(embeddings[i]), torch.clone(embeddings[index])])\n","\n","#                 eval_pairs = true_model(node_features, edge_features.to(\"cuda\"), from_idx.to(\"cuda\"), to_idx.to(\"cuda\"),\n","#                                    graph_idx.to(\"cuda\"), n_graphs, is_test=True)\n","\n","#                 x, y = reshape_and_split_tensor(eval_pairs, 2)\n","#                 sim = compute_similarity(config, x, y)\n","#                 similarities.append(sim)\n","#                 counter += int(n_graphs/2)\n","\n","#             similarities = torch.cat(similarities, -1)\n","#             index_sorted = torch.argsort(similarities, descending=True)\n","#             top_k = index_sorted[:200]\n","\n","#             top_k_list, scores = [], []\n","#             top_k_list.extend([functions_ids[k] for k in top_k])\n","#             scores.extend([similarities[k].item() for k in top_k])\n","\n","#             g_t = set(json.loads(row[\"ground_truth\"]))\n","#             true_labels = [1 if k_id in g_t else 0 for k_id in top_k_list]\n","#             gmn_answers.append((true_labels, len(g_t), scores))\n","\n","#         gmn_avg_p1, gmn_recal_p1, gmn_pre_p1 = extract_info(gmn_answers)\n","#         os.makedirs(gmn_info_path, exist_ok=True)\n","#         json.dump(list(gmn_avg_p1), open(os.path.join(gmn_info_path, \"ndcg_info.json\"), \"w\"))\n","#         json.dump(list(gmn_recal_p1), open(os.path.join(gmn_info_path, \"recall_info.json\"), \"w\"))\n","#         json.dump(list(gmn_pre_p1), open(os.path.join(gmn_info_path, \"precision_info.json\"), \"w\"))\n","\n","# infos.append((gmn_avg_p1, gmn_recal_p1, gmn_pre_p1))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lyF2AVbOSex2"},"outputs":[],"source":["# # GMN-PT-FT\n","\n","# import copy\n","# from evaluation import *\n","# from configure import *\n","# from dataset import *\n","# from utils import *\n","\n","# gmn_info_path = os.path.join(base_data_path, \"embeddings\", \"GMN-PT-FT\")\n","\n","# gpu = int(os.environ[\"CUDA_VISIBLE_DEVICES\"])\n","\n","# config = get_default_config()\n","# config['evaluation']['batch_size'] = 128\n","# dataset_params = config['data']['dataset_params']\n","# dataset_params['test_path'] = test_path.replace('.csv', '_CFG.csv')\n","\n","# gmn_base_path = os.path.join(base_path, \"Graph-Matching-Networks\")\n","\n","# tokenizer_path = \"/home/jovyan/work/olivetree/final_for_paper/tokenizer\"\n","# transformer_path = \"/home/jovyan/work/olivetree/final_for_paper/models/next_sentence_prediction_bert_normal_mask30/checkpoint-67246\"\n","# gmn_tokenizer, _ = load_olivetree_model_freezed(tokenizer_path, transformer_path,\n","#                                                 mlm=False if \"next\" in transformer_path else True)\n","\n","# test_set = GraphFunctionSimilarityDataset(dataset_params, mode='test')\n","\n","# gmn_model_name = \"GMN_pt_ft_epoch15_step18804_auc_val=0.9969054484122147.pt\"\n","# model = torch.load(os.path.join(gmn_base_path, \"models\", \"pt_freezed_ft_2\", gmn_model_name))\n","# model.to(\"cuda\")\n","# model.eval()\n","\n","# with torch.no_grad():\n","\n","#     functions_ids = test_set._df[\"function_id\"].to_list()\n","#     queries = test_set._df[~test_set._df['ground_truth'].isnull()]\n","#     splits = np.array_split(queries, 4)\n","#     queries = splits[gpu]\n","\n","#     # memoization of tokenized nodes for each functions\n","#     print(\"Tokenization and pre-computation of nodes embeddings...\")\n","#     embeddings = pre_compute_nodes_features(test_set._df, gmn_tokenizer, model._pt_model)\n","#     print(len(embeddings))\n","\n","#     gmn_answers = []\n","#     for index, row in tqdm(queries.iterrows(), total=len(queries)):\n","#         if os.path.exists(os.path.join(gmn_info_path, f\"index_{str(index).zfill(4)}_gpu_{gpu}.json\")):\n","#             continue\n","#         test_data_iter = test_set.list_cfg(config['evaluation']['batch_size'], query_idx=index, stack=False, capping=True)\n","\n","#         counter = 0\n","#         similarities = []\n","#         while not test_set.is_empty():\n","\n","#             batch = next(test_data_iter)\n","#             node_features, edge_features, from_idx, to_idx, graph_idx, n_graphs = get_graph(batch)\n","\n","#             node_features = []\n","#             for i in range(counter, counter+int(n_graphs/2)):\n","#                 if i < len(embeddings):\n","#                     node_features.extend([torch.clone(embeddings[i]).to(\"cuda\"), torch.clone(embeddings[index]).to(\"cuda\")])\n","\n","#             eval_pairs = model(node_features, edge_features.to(\"cuda\"), from_idx.to(\"cuda\"), to_idx.to(\"cuda\"),\n","#                                graph_idx.to(\"cuda\"), n_graphs, is_test=True)\n","\n","#             x, y = reshape_and_split_tensor(eval_pairs, 2)\n","#             sim = compute_similarity(config, x, y)\n","#             similarities.append(sim)\n","#             counter += int(n_graphs/2)\n","\n","#         similarities = torch.cat(similarities, -1)\n","#         index_sorted = torch.argsort(similarities, descending=True)\n","#         top_k = index_sorted[:200]\n","\n","#         top_k_list, scores = [], []\n","#         top_k_list.extend([functions_ids[k] for k in top_k])\n","#         scores.extend([similarities[k].item() for k in top_k])\n","\n","#         g_t = set(json.loads(row[\"ground_truth\"]))\n","#         true_labels = [1 if k_id in g_t else 0 for k_id in top_k_list]\n","#         gmn_answers.append((true_labels, len(g_t), scores))\n","\n","#         with open(os.path.join(gmn_info_path, f\"index_{str(index).zfill(4)}_gpu_{gpu}.json\"), \"w\") as f:\n","#             json.dump([true_labels, len(g_t), scores], f)\n","\n","#     gmn_avg_p1, gmn_recal_p1, gmn_pre_p1 = extract_info(gmn_answers)\n","\n","#     with open(os.path.join(gmn_info_path, f\"{test_name}_{gpu}.json\"), \"w\") as f:\n","#         json.dump([gmn_avg_p1, gmn_recal_p1, gmn_pre_p1], f)\n","\n","# # infos.append((gmn_avg_p1, gmn_recal_p1, gmn_pre_p1))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"d81355yJSex2"},"outputs":[],"source":["# TREX\n","\n","TREX_info = test_path.replace(\".csv\", \"_TREX.csv\")\n","TREX_path = os.path.join(base_data_path, \"embeddings\", \"TREX\")\n","\n","df_trex = pd.read_csv(TREX_info, sep='\\t')\n","df_trex = df_trex.where(pd.notnull(df_trex), None)\n","\n","trex_functions_ids = df_trex['function_id'].tolist()\n","\n","os.makedirs(TREX_path, exist_ok=True)\n","with open(os.path.join(TREX_path, f\"functions_ids.json\"), \"w\") as f:\n","    json.dump(trex_functions_ids, f)\n","\n","trex_embeddings = df_trex['embedding'].to_list()\n","\n","trex_embeddings = list(map(lambda x: torch.from_numpy(np.array(json.loads(x))), trex_embeddings))\n","matrix = torch.stack(trex_embeddings)\n","torch.save(matrix, os.path.join(TREX_path, f\"embeddings_layer_{-1}.pt\"))\n","\n","trex_answers = find_top_k_similar(TREX_path, df_trex, 32, -1, 200)\n","trex_avg_p1, trex_recal_p1, trex_pre_p1 = extract_info(trex_answers)\n","\n","with open(os.path.join(TREX_path, f\"{test_name}.json\"), \"w\") as f:\n","    json.dump([trex_avg_p1, trex_recal_p1, trex_pre_p1], f)\n","\n","# infos.append((trex_avg_p1, trex_recal_p1, trex_pre_p1))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"udAZU7SRSex2","outputId":"91e1645d-755d-4b31-9bf3-1b90b8fcd96a","colab":{"referenced_widgets":["b2b5f4d0bd7d4574a9ab66eeabc92288","58a72dbfb8b64aa39beace81f9e35dd3"]}},"outputs":[{"name":"stdout","output_type":"stream","text":["58773\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b2b5f4d0bd7d4574a9ab66eeabc92288","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/5000 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["On inference it took 1.0469988538668706 seconds on avg\n","In total it took 163.6401469707489 seconds\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"58a72dbfb8b64aa39beace81f9e35dd3","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/5000 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"}],"source":["# SAFE\n","\n","SAFE_info = test_path.replace(\".csv\", \"_SAFE.csv\")\n","SAFE_path = os.path.join(base_data_path, \"embeddings\", \"SAFE\")\n","\n","df_safe = pd.read_csv(SAFE_info, sep='\\t')\n","df_safe = df_safe.where(pd.notnull(df_safe), None)\n","# print(df_safe.keys())\n","df_safe.rename(columns = {'ot_function_id':'function_id'}, inplace = True)\n","# print(df_safe.keys())\n","\n","safe_functions_ids = df_safe['function_id'].tolist()\n","\n","os.makedirs(SAFE_path, exist_ok=True)\n","with open(os.path.join(SAFE_path, f\"functions_ids.json\"), \"w\") as f:\n","    json.dump(safe_functions_ids, f)\n","\n","safe_embeddings = df_safe['embedding'].to_list()\n","safe_embeddings = list(map(lambda x: torch.from_numpy(embeddingToNp(x)), safe_embeddings))\n","matrix = torch.stack(safe_embeddings)\n","torch.save(matrix, os.path.join(SAFE_path, f\"embeddings_layer_{-1}.pt\"))\n","\n","safe_answers = find_top_k_similar(SAFE_path, df_safe, 32, -1, 200)\n","safe_avg_p1, safe_recal_p1, safe_pre_p1 = extract_info(safe_answers)\n","\n","with open(os.path.join(SAFE_path, f\"{test_name}.json\"), \"w\") as f:\n","    json.dump([safe_avg_p1, safe_recal_p1, safe_pre_p1], f)\n","\n","# infos.append((safe_avg_p1, safe_recal_p1, safe_pre_p1))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gmmqUPwwSex2"},"outputs":[],"source":["# # Asm2Vec\n","# import json, sys\n","# from scipy import spatial\n","\n","# df_ext = pd.read_csv(os.path.join(base_data_path, \"test_functions_nDCG_extended.csv\"), sep='\\t')\n","# df_ext = df_ext.where(pd.notnull(df_ext), None)\n","# print(df_ext.keys())\n","\n","# missing = 0\n","\n","# paths = []\n","# asm2vec_functions_ids = []\n","# g_t = []\n","\n","# asm2vec_embeddings = []\n","\n","# base_asm2vec_path = os.path.join(base_path, \"asm2vec\", \"asm2vec-pytorch\")\n","# sys.path.append(base_asm2vec_path)\n","# import asm2vec\n","\n","# for row in tqdm(df_ext.values):\n","#     bin_info = row[-1]\n","#     tokens = bin_info.split('/')\n","#     base_func_path_a2v = os.path.join(base_asm2vec_path, \"disasm_testing\", tokens[0], tokens[1], tokens[2], tokens[3])\n","\n","#     if not os.path.exists(base_func_path_a2v):\n","#         print(f\"{base_func_path_a2v} does not exist\")\n","#         continue\n","\n","#     func_path_a2v = os.path.join(base_func_path_a2v, tokens[4])\n","#     if not os.path.exists(func_path_a2v):\n","#         func_path_a2v = os.path.join(base_func_path_a2v, f\"sym.{tokens[4]}\")\n","\n","#         if not os.path.exists(func_path_a2v):\n","#             func_path_a2v = os.path.join(base_func_path_a2v, f\"dbg.{tokens[4]}\")\n","\n","#             if not os.path.exists(func_path_a2v):\n","#                 print(f\"{base_func_path_a2v} -> {tokens[4]} does not exist\")\n","#                 missing += 1\n","#                 continue\n","\n","#     paths.append(func_path_a2v)\n","#     asm2vec_functions_ids.append(row[0])\n","#     g_t.append(row[3])\n","\n","#     assert(len(paths) == len(asm2vec_functions_ids) == len(g_t))\n","\n","# if missing > 0:\n","#     print(f\"{missing} missing files\")\n","\n","\n","# # computing the embeddings\n","# asm2vec_model_path = os.path.join(base_asm2vec_path, \"model\", \"asm2vec_model.pt\")\n","# asm2vec_model, a2v_tokens = asm2vec.utils.load_model(asm2vec_model_path, device='cuda')\n","\n","# a2v_functions, a2v_tokens_new = asm2vec.utils.load_data(paths)\n","# a2v_tokens.update(a2v_tokens_new)\n","# asm2vec_model.update(len(a2v_functions), a2v_tokens.size())\n","# asm2vec_model = asm2vec_model.to('cuda')\n","\n","# # train function embedding\n","# asm2vec_model = asm2vec.utils.train(\n","#     a2v_functions,\n","#     a2v_tokens,\n","#     model=asm2vec_model,\n","#     epochs=10,\n","#     device='cuda',\n","#     mode='test',\n","#     learning_rate=0.02\n","# )\n","\n","# asm2vec_data_path = os.path.join(base_data_path, \"embeddings\", \"ASM2VEC\")\n","\n","# embeddings = asm2vec_model.to('cpu').embeddings_f(torch.tensor(range(len(a2v_functions))))\n","# embeddings = list(map(lambda x: x.detach().cpu(), embeddings))\n","# matrix = torch.stack(embeddings)\n","# torch.save(matrix, os.path.join(asm2vec_data_path, f\"embeddings_layer_{-1}.pt\"))\n","\n","# with open(os.path.join(asm2vec_data_path, f\"functions_ids.json\"), \"w\") as f:\n","#     json.dump(asm2vec_functions_ids, f)\n","\n","# rows = list(zip(asm2vec_functions_ids, g_t))\n","# pd_kv = pd.DataFrame(rows, columns=[\"function_id\", \"ground_truth\"])\n","\n","# asm2vec_answers = find_top_k_similar(asm2vec_data_path, pd_kv, 1, -1, 200)\n","# asm2_avg_p1, asm2_recal_p1, asm2_pre_p1 = extract_info(asm2vec_answers)\n","# infos.append((asm2_avg_p1, asm2_recal_p1, asm2_pre_p1))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"R51kd8EFeugb"},"outputs":[],"source":["# olivetree\n","ot_lst = [\n","    #(\"nsp_normal_mask30_avg\", \"epoch-1\", True, False),\n","    #(\"nsp_normal_mask30_avg_cos_emb_loss\", \"epoch-2\", True, False),\n","    #(\"mlm_normal_mask30_avg\", \"epoch-1\", True, False),\n","    #(\"from_scratch_normal_avg\", \"epoch-6\", True, False),\n","    #(\"nsp_normal_mask30_triplet_loss\", \"epoch-16\", True, False),\n","    #(\"mlm_normal_mask30_triplet_loss\", \"epoch-12\", True, False),\n","    (\"nsp_normal_unigram_mask30_triplet_loss\", \"epoch-10\", True, False),\n","    (\"nsp_normal_whitespace_mask30_triplet_loss\", \"epoch-9\", True, False),\n","    (\"nsp_normal_whitespace2_mask30_triplet_loss\", \"epoch-15\", True, False),\n","    (\"from_scratch_normal_triplet_loss\", \"epoch-18\", True, False)\n","]\n","\n","for olivetree_model_name, olivetree_checkpoint, is_fine_tuned, is_cls in ot_lst:\n","    if is_fine_tuned:\n","        olivetree_model_path = os.path.join(base_olivetree_finetuned, olivetree_model_name, olivetree_checkpoint)\n","    else:\n","        olivetree_model_path = os.path.join(base_olivetree, olivetree_model_name, olivetree_checkpoint)\n","\n","    focus_layer = ol_focus_layer if not is_fine_tuned else -1\n","\n","    # time_start = time.time()\n","    if \"unigram\" in olivetree_model_name:\n","        t_path = u_tokenizer_path\n","    elif \"whitespace2\" in olivetree_model_name:\n","        t_path = w2_tokenizer_path\n","    elif \"whitespace\" in olivetree_model_name:\n","        t_path = w_tokenizer_path\n","    else:\n","        t_path = tokenizer_path\n","\n","    ot_functions_ids, ot_embeddings_list = compute_embeddings_olivetree(t_path, olivetree_model_path, df, focus_layer, 32, is_cls=is_cls)\n","\n","    ot_path = os.path.join(base_data_path, \"embeddings\", olivetree_model_name, olivetree_checkpoint)\n","    os.makedirs(ot_path, exist_ok=True)\n","    with open(os.path.join(ot_path, f\"functions_ids.json\"), \"w\") as f:\n","        json.dump(ot_functions_ids, f)\n","\n","    #for layer_id in range(len(ot_embeddings_list)):\n","    embeddings = ot_embeddings_list\n","    matrix = torch.stack(embeddings)\n","    torch.save(matrix, os.path.join(ot_path, f\"embeddings_layer_{focus_layer}.pt\"))\n","\n","    olivetree_answers = find_top_k_similar(ot_path, df, 32, focus_layer, 200)\n","    ol_avg_p1, ol_recal_p1, ol_pre_p1 = extract_info(olivetree_answers)\n","\n","    # infos.append((ol_avg_p1, ol_recal_p1, ol_pre_p1))\n","    # time_end = time.time() - time_start\n","\n","    # print(f\"BinBert takes {time_end} to complete test\")\n","\n","    with open(os.path.join(ot_path, f\"{test_name}.json\"), \"w\") as f:\n","        json.dump([ol_avg_p1, ol_recal_p1, ol_pre_p1], f)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7P4wUZ19Sex2"},"outputs":[],"source":["# palmtree lstm finetuned\n","pt_lst = [\n","    (\"epoch1_finetuning_lstm\", \"epoch=15-val_auc=0.9779.ckpt\", True),\n","    (\"from_scratch_finetuning_lstm\", \"epoch=18-val_auc=0.9613.ckpt\", True)\n","]\n","\n","for palmtree_model_name, palmtree_checkpoint, is_fine_tuned in pt_lst:\n","    palmtree_model_path = os.path.join(base_palmtree_finetuned, palmtree_model_name, palmtree_checkpoint)\n","\n","    focus_layer = pt_focus_layer if not is_fine_tuned else pt_focus_layer + 1\n","\n","    pt_functions_ids, pt_embeddings_list = compute_embeddings_palmtree_lstm(vocab_path, palmtree_model_path, df, 32)\n","    pt_path = os.path.join(base_data_path, \"embeddings\", palmtree_model_name, palmtree_checkpoint)\n","    os.makedirs(pt_path, exist_ok=True)\n","\n","    with open(os.path.join(pt_path, f\"functions_ids.json\"), \"w\") as f:\n","        json.dump(pt_functions_ids, f)\n","\n","    #for layer_id in range(len(pt_embeddings_list)):\n","\n","    embeddings = pt_embeddings_list\n","    matrix = torch.stack(embeddings)\n","    torch.save(matrix, os.path.join(pt_path, f\"embeddings_layer_{focus_layer}.pt\"))\n","\n","    palmtree_answers = find_top_k_similar(pt_path, df, 32, focus_layer, 200)\n","    pt_avg_p1, pt_recal_p1, pt_pre_p1 = extract_info(palmtree_answers)\n","\n","    # infos.append((pt_avg_p1, pt_recal_p1, pt_pre_p1))\n","\n","    with open(os.path.join(pt_path, f\"{test_name}.json\"), \"w\") as f:\n","        json.dump([pt_avg_p1, pt_recal_p1, pt_pre_p1], f)"]},{"cell_type":"markdown","metadata":{"id":"EL83G0oUSex2"},"source":["### Plotting results"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_wbuBHpfeugf"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","from scipy.interpolate import make_interp_spline\n","\n","def print_graph(scores, stds, max_pos, file_name, label_y, titles, image_title=None):\n","\n","    plt.clf()\n","    plt.grid()\n","\n","    plt.xlabel(\"Number of Nearest Results\")\n","    plt.ylabel(label_y)\n","    plt.ylim([0, 1])\n","\n","#     cmap = plt.get_cmap('brg')\n","#     colors = [cmap(i) for i in np.linspace(0.2, 0.9, len(titles))]\n","\n","    for i, title in enumerate(titles):\n","\n","        x = range(0, max_pos)\n","        y = scores[i][:max_pos]\n","\n","#         X_Y_Spline = make_interp_spline(x, y)\n","#         X_ = np.linspace(0, max_pos, 500)\n","#         Y_ = X_Y_Spline(X_)\n","        y_std_plus = y + stds[i][:max_pos]\n","        y_std_minus = y - stds[i][:max_pos]\n","\n","#         title == \"GEM-BOW\"\n","#         title == \"GMN-PT-FT\"\n","#         or title == \"GMN-PT\"\n","#         or title == \"GMN-BOW\"\n","#         title == \"Asm2Vec\"\n","        if title == \"BinBert-FT\":\n","            color = \"tab:blue\"\n","        elif title == \"BinBert-MLM-FT\":\n","            color = \"tab:orange\"\n","        elif title == \"BinBert-FS\":\n","            color = \"tab:green\"\n","        elif title == \"PalmTree-FT\":\n","            color = \"tab:red\"\n","        elif title == \"SAFE\":\n","            color = \"tab:olive\"\n","        elif title == \"GEN-BOW\":\n","            color = \"tab:purple\"\n","        elif title == \"GMN-BOW\":\n","            color = \"tab:cyan\"\n","        elif title == \"TREX-FT\":\n","            color = \"tab:brown\"\n","\n","        plt.plot(x, y, label=title, color=color, linewidth=0.7, linestyle=\"solid\")\n","        plt.fill_between(x, y, y_std_plus, alpha=.4, color=color, linewidth=0)\n","        plt.fill_between(x, y, y_std_minus, alpha=.4, color=color, linewidth=0)\n","#         plt.plot(x, y_std_plus, color=color, linewidth=1, linestyle=\"dashed\")\n","#         plt.plot(x, y_std_minus, color=color, linewidth=1, linestyle=\"dashed\")\n","\n","    if image_title is not None:\n","        plt.title(image_title)\n","\n","    plt.legend(prop={'size': 8})\n","    #plt.legend()\n","    plt.savefig(file_name, dpi=500, format=\"pdf\")\n","    plt.close(file_name)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xI5c2JF2Sex3"},"outputs":[],"source":["from texttable import Texttable\n","\n","def print_table(info, titles):\n","    t = Texttable(max_width=1000)\n","    # idx = [4, 9, 14, 19, 24, 29, 34, 39, 44, 49]\n","    idx = [4, 9, 24]\n","    hit_labels = ['model'] + [f'hit-{i+1}' for i in idx]\n","    t.add_row(hit_labels)\n","\n","    for i, model in enumerate(titles):\n","        local_info = [info[i][j] for j in idx]\n","        local_info.insert(0, model)\n","        t.add_row(local_info)\n","\n","    print(t.draw())"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":283},"executionInfo":{"elapsed":3210,"status":"ok","timestamp":1648208262408,"user":{"displayName":"marco mormando","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04156205142238414005"},"user_tz":-60},"id":"yqu1CU5Yeugf","outputId":"4beed85d-c3d0-45fe-d688-ad6a24e77aba"},"outputs":[{"name":"stdout","output_type":"stream","text":["Results nDCG\n","+----------------+-------+--------+--------+\n","| model          | hit-5 | hit-10 | hit-25 |\n","+----------------+-------+--------+--------+\n","| BinBert-FT     | 0.834 | 0.747  | 0.740  |\n","+----------------+-------+--------+--------+\n","| BinBert-MLM-FT | 0.813 | 0.718  | 0.708  |\n","+----------------+-------+--------+--------+\n","| BinBert-FS     | 0.514 | 0.399  | 0.380  |\n","+----------------+-------+--------+--------+\n","| PalmTree-FT    | 0.694 | 0.567  | 0.542  |\n","+----------------+-------+--------+--------+\n","| GEN-BOW        | 0.614 | 0.495  | 0.475  |\n","+----------------+-------+--------+--------+\n","| TREX-FT        | 0.781 | 0.678  | 0.665  |\n","+----------------+-------+--------+--------+\n","| SAFE           | 0.638 | 0.511  | 0.494  |\n","+----------------+-------+--------+--------+\n","\n","Results Precision\n","+----------------+-------+--------+--------+\n","| model          | hit-5 | hit-10 | hit-25 |\n","+----------------+-------+--------+--------+\n","| BinBert-FT     | 0.785 | 0.592  | 0.315  |\n","+----------------+-------+--------+--------+\n","| BinBert-MLM-FT | 0.759 | 0.562  | 0.298  |\n","+----------------+-------+--------+--------+\n","| BinBert-FS     | 0.395 | 0.239  | 0.120  |\n","+----------------+-------+--------+--------+\n","| PalmTree-FT    | 0.605 | 0.399  | 0.203  |\n","+----------------+-------+--------+--------+\n","| GEN-BOW        | 0.528 | 0.342  | 0.176  |\n","+----------------+-------+--------+--------+\n","| TREX-FT        | 0.719 | 0.519  | 0.273  |\n","+----------------+-------+--------+--------+\n","| SAFE           | 0.538 | 0.344  | 0.177  |\n","+----------------+-------+--------+--------+\n","\n","Results Recall\n","+----------------+-------+--------+--------+\n","| model          | hit-5 | hit-10 | hit-25 |\n","+----------------+-------+--------+--------+\n","| BinBert-FT     | 0.389 | 0.553  | 0.696  |\n","+----------------+-------+--------+--------+\n","| BinBert-MLM-FT | 0.374 | 0.523  | 0.658  |\n","+----------------+-------+--------+--------+\n","| BinBert-FS     | 0.193 | 0.228  | 0.280  |\n","+----------------+-------+--------+--------+\n","| PalmTree-FT    | 0.291 | 0.368  | 0.452  |\n","+----------------+-------+--------+--------+\n","| GEN-BOW        | 0.251 | 0.315  | 0.395  |\n","+----------------+-------+--------+--------+\n","| TREX-FT        | 0.352 | 0.483  | 0.606  |\n","+----------------+-------+--------+--------+\n","| SAFE           | 0.260 | 0.322  | 0.405  |\n","+----------------+-------+--------+--------+\n"]},{"data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"},"output_type":"display_data"}],"source":["model_lists = [\n","    (\"nsp_normal_mask30_triplet_loss\", \"epoch-16\", \"BinBert-FT\"),\n","    (\"mlm_normal_mask30_triplet_loss\", \"epoch-12\", \"BinBert-MLM-FT\"),\n","    #(\"nsp_normal_unigram_mask30_triplet_loss\", \"epoch-10\", \"BinBert-FT-Unigram\"),\n","    #(\"nsp_normal_whitespace_mask30_triplet_loss\", \"epoch-9\", \"BinBert-FT-Whitespace\"),\n","    #(\"nsp_normal_whitespace2_mask30_triplet_loss\", \"epoch-15\", \"BinBert-FT-Whitespace2\"),\n","    (\"from_scratch_normal_triplet_loss\", \"epoch-18\", \"BinBert-FS\"),\n","    (\"epoch1_finetuning_lstm\", \"epoch=15-val_auc=0.9779.ckpt\", \"PalmTree-FT\"),\n","\n","    # (\"from_scratch_finetuning_lstm\", \"epoch=18-val_auc=0.9613.ckpt\", \"\"),\n","    (\"GEN-BOW\", \"\", \"GEN-BOW\"),\n","    # (\"GMN-BOW\", \"\", \"GMN-BOW\"),\n","    (\"TREX\", \"\", \"TREX-FT\"),\n","    (\"SAFE\", \"\", \"SAFE\"),\n","]\n","\n","titles = list(map(lambda x: x[2], model_lists))\n","\n","res_names = [\n","    \"test_functions_others_DEFINITIVE_nDCG.csv.json\",\n","]\n","\n","n, r, p = [], [], []\n","sn, sr, sp = [], [], []\n","\n","for model_name, checkpoint, _ in model_lists:\n","\n","    json_base_path = os.path.join(base_data_path, \"embeddings\", model_name, checkpoint)\n","\n","    n_local, r_local, p_local = [], [], []\n","    for res_name in res_names:\n","        res_json = json.load(open(os.path.join(json_base_path, res_name)))\n","        n_local.append(res_json[0])\n","        r_local.append(res_json[1])\n","        p_local.append(res_json[2])\n","\n","    n.append(np.mean(n_local, axis=0))\n","    r.append(np.mean(r_local, axis=0))\n","    p.append(np.mean(p_local, axis=0))\n","\n","    sn.append(np.std(n_local, axis=0))\n","    sr.append(np.std(r_local, axis=0))\n","    sp.append(np.std(p_local, axis=0))\n","\n","print_graph(n, sn, 31, os.path.join(base_res_path, \"nDCG_functions_extrinsic.pdf\"), \"nDCG\",\n","            titles, image_title=\"Extrinsic Similarity at Functions Level\")\n","print_graph(p, sp, 31, os.path.join(base_res_path, f\"precision_functions_extrinsic.pdf\"), \"Precision\",\n","            titles, image_title=\"Extrinsic Similarity at Functions Level\")\n","print_graph(r, sr, 31, os.path.join(base_res_path, f\"recall_functions_extrinsic.pdf\"), \"Recall\",\n","            titles, image_title=\"Extrinsic Similarity at Functions Level\")\n","\n","print(\"Results nDCG\")\n","print_table(n, titles)\n","print()\n","print(\"Results Precision\")\n","print_table(p, titles)\n","print()\n","print(\"Results Recall\")\n","print_table(r, titles)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0Ndyb-gHSex3"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.12"},"widgets":{"application/vnd.jupyter.widget-state+json":{}}},"nbformat":4,"nbformat_minor":0}